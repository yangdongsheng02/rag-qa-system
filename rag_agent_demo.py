# ä¸€ å¯¼å…¥åº“
import os  # æ“ä½œç³»ç»Ÿæ¥å£,ç”¨äºæ–‡ä»¶æ“ä½œ
from dotenv import load_dotenv

load_dotenv()  # è¿™ä¼šè‡ªåŠ¨ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
import warnings  # å¯¼å…¥Pythonçš„warningsæ¨¡å—,ç”¨äºå¤„ç†è­¦å‘Š

warnings.filterwarnings('ignore', category=DeprecationWarning)  # å¿½ç•¥DeprecationWarningï¼ˆå¼ƒç”¨è­¦å‘Š)
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'  # å›½å†…é•œåƒåœ°å€åŠ é€Ÿå›½å†…è®¿é—® Hugging Face æ¨¡å‹å’Œæ•°æ®é›†

from langchain_text_splitters import \
    RecursiveCharacterTextSplitter  # æ–‡æœ¬åˆ†å‰²å™¨,ç”¨äºå°†é•¿æ–‡æ¡£åˆ†å‰²æˆå°å—,ä¾¿äºæ¨¡å‹å¤„ç†å’Œæ£€ç´¢,Recursive(é€’å½’)æ„å‘³ç€å®ƒä¼šæ™ºèƒ½åœ°æŒ‰ç…§å±‚æ¬¡ç»“æ„åˆ†å‰²æ–‡æœ¬
from langchain_community.document_loaders import TextLoader, PyPDFLoader, DirectoryLoader  # æ–‡æ¡£åŠ è½½å™¨:æ”¯æŒTXT,PDFç­‰å¤šç§æ ¼å¼
from langchain_huggingface import HuggingFaceEmbeddings  # åµŒå…¥æ¨¡å‹:å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡è¡¨ç¤º,ç”¨äºç›¸ä¼¼æ€§è®¡ç®—
from langchain_chroma import Chroma  # å‘é‡æ•°æ®åº“:å­˜å‚¨å’Œæ£€ç´¢åµŒå…¥å‘é‡,å­˜å‚¨æ‰€æœ‰æ–‡æœ¬å—çš„å‘é‡,å¿«é€ŸæŸ¥æ‰¾ç›¸ä¼¼å†…å®¹
from langchain_core.prompts import PromptTemplate  # æç¤ºè¯æ¨¡æ¿,å®šä¹‰å¦‚ä½•ç»„ç»‡é—®é¢˜,ä¸Šä¸‹æ–‡å’ŒæŒ‡ä»¤.åˆ›å»ºæ ‡å‡†åŒ–çš„æç¤ºè¯,æé«˜æ¨¡å‹å›ç­”è´¨é‡
from langchain_core.runnables import RunnablePassthrough, \
    RunnableLambda  # LangChainçš„æµç¨‹æ§åˆ¶ç»„ä»¶, RunnablePassthrough:å°†è¾“å…¥åŸå°ä¸åŠ¨ä¼ é€’ç»™ä¸‹ä¸€æ­¥,åœ¨RAGé“¾ä¸­ä¼ é€’ç”¨æˆ·é—®é¢˜
from langchain_core.output_parsers import \
    StrOutputParser  # è¾“å‡ºè§£æå™¨, StrOutputParser:å°†æ¨¡å‹è¾“å‡ºè§£æä¸ºå­—ç¬¦ä¸²,ç¡®ä¿æœ€ç»ˆè¾“å‡ºçš„æ˜¯çº¯æ–‡æœ¬æ ¼å¼(ä¸ç„¶å¯èƒ½æ˜¯AImessa(å†…å®¹)çš„å½¢å¼)
import requests  # HTTPè¯·æ±‚åº“,è°ƒç”¨MiniMax APIæ¥å£
import json  # jsonæ•°æ®å¤„ç†åº“,å¤„ç†APIè¯·æ±‚å’Œå“åº”çš„JSONæ•°æ®
import gradio as gr  # å¯¼å…¥gradioç”¨äºæ„å»ºWebç•Œé¢ã€‚
import re  # æ­£åˆ™è¡¨è¾¾å¼


# äºŒ é…ç½®ä¿¡æ¯ç±»
class Config:
    '''
    é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®å‚æ•°,ä¾¿äºç»Ÿä¸€ç®¡ç†
    '''
    KNOWLEDGE_BASE_PATH = './knowledge_base'  # å®šä¹‰çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„,éœ€è¦åœ¨å¯¼å…¥åº“æ—¶æŒ‡å®šç±»å‹
    PERSIST_DIRECTORY = './chroma_db'  # å‘é‡æ•°æ®åº“çš„ä¿å­˜ç›®å½•,ä¸‹æ¬¡å¯åŠ¨æ—¶å¯ç›´æ¥åŠ è½½,æ— éœ€é‡æ–°æ„å»º
    EMBED_MODEL_NAME = 'BAAI/bge-small-zh'  # åµŒå…¥æ¨¡å‹åç§°,åŒ—äº¬æ™ºæºç ”ç©¶é™¢çš„ä¸­æ–‡å°æ¨¡å‹,ä¸“é—¨ä¸ºä¸­æ–‡ä¼˜åŒ–çš„åµŒå…¥æ¨¡å‹
    # MiniMax APIé…ç½®
    # ä»ç¯å¢ƒå˜é‡è¯»å–
    MM_API_KEY = os.environ.get('MINIMAX_API_KEY', '')  # å¦‚æœæ²¡æ‰¾åˆ°ç¯å¢ƒå˜é‡ï¼Œåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    MM_GROUP_ID = os.environ.get('MINIMAX_GROUP_ID', '')
    MM_API_URL = "https://api.minimaxi.com/v1/text/chatcompletion_v2"  # APIåœ°å€


# ä¸‰ è¾…åŠ©å‡½æ•°(è¿™é‡Œç”¨æ¥æ¸…æ´—æ•°æ®)
def clean_markdown_content(docs):
    """æ¸…æ´—Markdownå†…å®¹çš„å‡½æ•°ï¼Œå¤„ç†Obsidianå†…éƒ¨é“¾æ¥å’Œå›¾ç‰‡æ ‡è®°"""
    for doc in docs:
        content = doc.page_content

        # 1. å¤„ç†Obsidianå†…éƒ¨é“¾æ¥ [[ç›®æ ‡ç¬”è®°|åˆ«å]] è½¬æ¢ä¸º"åˆ«åï¼ˆç›®æ ‡ç¬”è®°ï¼‰"
        # å¤„ç†å¸¦æœ‰åˆ«åçš„é“¾æ¥
        content = re.sub(r'\[\[([^|\]]+)\|([^\]]+)\]\]', r'\2ï¼ˆ\1ï¼‰', content)
        # å¤„ç†æ— åˆ«åçš„é“¾æ¥
        content = re.sub(r'\[\[([^\]]+)\]\]', r'\1', content)

        # 2. å¤„ç†å›¾ç‰‡æ ‡è®°ï¼Œä¿ç•™æè¿°æ–‡æœ¬
        # å°† ![æè¿°](å›¾ç‰‡åœ°å€) æ›¿æ¢ä¸º [å›¾ç‰‡ï¼šæè¿°]
        content = re.sub(r'!\[([^\]]*)\]\([^)]+\)', r'[å›¾ç‰‡ï¼š\1]', content)

        doc.page_content = content
    return docs


# å›› æ„å»ºçŸ¥è¯†åº“å‡½æ•°
def build_knowledge_base():
    '''åŠ è½½,åˆ†å‰²æ–‡æ¡£,å¹¶åˆ›å»ºå‘é‡æ•°æ®åº“'''
    print('å¼€å§‹æ„å»ºçŸ¥è¯†åº“...')

    # 1.æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    dir_path = Config.KNOWLEDGE_BASE_PATH  # è·å–é…ç½®ä¸­çš„æ–‡ä»¶è·¯å¾„

    if not os.path.exists(dir_path):
        # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºç©ºç›®å½•
        print(f"çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºç›®å½•: {dir_path}")
        os.makedirs(dir_path, exist_ok=True)
        print(f"å·²åˆ›å»ºçŸ¥è¯†åº“ç›®å½•: {dir_path}")
        print(f"è¯·å°†çŸ¥è¯†åº“å¤åˆ¶åˆ° {dir_path} ç›®å½•ä¸­ï¼Œç„¶åé‡æ–°è¿è¡Œç¨‹åºã€‚")
        # è¿”å›Noneï¼Œè¡¨ç¤ºæ²¡æœ‰æ„å»ºçŸ¥è¯†åº“
        return None

    print(f"ä»ç›®å½•åŠ è½½çŸ¥è¯†åº“: {dir_path}")

    # 2. ä½¿ç”¨DirectoryLoaderåŠ è½½æ‰€æœ‰.mdæ–‡ä»¶
    loader = DirectoryLoader(
        path=dir_path,
        glob="**/*.md",  # åŒ¹é…æ‰€æœ‰.mdæ–‡ä»¶
        loader_cls=TextLoader,
        loader_kwargs={'encoding': 'utf-8'},  # ä½¿ç”¨UTF-8ç¼–ç 
        exclude=["**/.obsidian/**", "**/é™„ä»¶/**", "**/assets/**"],  # æ’é™¤ç‰¹å®šç›®å½•
        show_progress=True,  # æ˜¾ç¤ºåŠ è½½è¿›åº¦
        use_multithreading=True  # ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿ
    )

    # 3.åŠ è½½æ–‡æ¡£
    documents = loader.load()  # loader.load():æ‰§è¡Œæ–‡æ¡£åŠ è½½,è¿”å›ä¸€ä¸ªæ–‡æ¡£å¯¹è±¡åˆ—è¡¨,PDFæ–‡æ¡£æ¯é¡µä¸ºä¸€ä¸ªDocumentå¯¹è±¡ï¼ŒTXTæ–‡æ¡£æ•´ä¸ªæ–‡ä»¶ä¸ºä¸€ä¸ªDocumentå¯¹è±¡
    print(f"å·²åŠ è½½æ–‡æ¡£ï¼Œå…± {len(documents)} ä¸ª.mdæ–‡ä»¶")
    if len(documents) == 0:
        print("çŸ¥è¯†åº“ç›®å½•ä¸­æ²¡æœ‰Markdownæ–‡ä»¶")
        print(f"è¯·å°†ç¬”è®°å¤åˆ¶åˆ° {dir_path} ç›®å½•ä¸­")
        return None

    # 4. æ¸…æ´—Markdownå†…å®¹ï¼ˆå¤„ç†å†…éƒ¨é“¾æ¥ã€å›¾ç‰‡ç­‰ï¼‰
    documents = clean_markdown_content(documents)
    print("å·²å®ŒæˆMarkdownå†…å®¹æ¸…æ´—")

    # 5.åˆ›å»ºæ–‡æœ¬åˆ†å‰²å™¨,åˆ†å‰²æ–‡æœ¬ä¸ºå°å—,ä¾¿äºæ¨¡å‹å¤„ç†(LLMæœ‰è¾“å…¥é•¿åº¦é™åˆ¶)
    text_splitter = RecursiveCharacterTextSplitter(  # recursiveé€’å½’,æŒ‰å±‚æ™ºèƒ½åˆ‡å‰²
        chunk_size=500,  # æ¯ä¸ªæ–‡æœ¬å—æœ€å¤š500å­—ç¬¦
        chunk_overlap=50,  # å—ä¹‹é—´çš„é‡å å­—ç¬¦,ä¿æŒä¸Šä¸‹æ–‡,ç›¸é‚»å—é‡å 50å­—ç¬¦ï¼Œé˜²æ­¢ä¿¡æ¯å‰²è£‚
        separators=["\n\n", "\n# ", "\n## ", "\n### ", "\n", "ã€‚", "ï¼Œ", " ", ""]  # ä¼˜å…ˆæŒ‰æ®µè½å’Œæ ‡é¢˜åˆ†å‰²
    )
    splits = text_splitter.split_documents(documents)  # æ‰§è¡Œåˆ†å‰²,è¿”å›æ›´å°çš„Documentå¯¹è±¡åˆ—è¡¨
    print(f"æ–‡æ¡£å·²åˆ†å‰²ä¸º {len(splits)} ä¸ªæ–‡æœ¬å—")

    # 6.åˆ›å»ºåµŒå…¥æ¨¡å‹(å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡),
    # åŠ è½½é¢„è®­ç»ƒçš„ä¸­æ–‡åµŒå…¥æ¨¡å‹
    embeddings = HuggingFaceEmbeddings(
        model_name=Config.EMBED_MODEL_NAME,
        model_kwargs={'device': 'cpu'},  # ä½¿ç”¨CPUï¼ŒGPUå¯æ”¹ä¸º 'cuda'
        encode_kwargs={'normalize_embeddings': True}
        # normalize_embeddings=Trueï¼šå½’ä¸€åŒ–åµŒå…¥å‘é‡ä½¿æ‰€æœ‰å‘é‡é•¿åº¦ä¸º1ï¼Œä¾¿äºä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—. å¤§æ¦‚æ„æ€å°±æ˜¯æŠŠé‚£äº›å½±å“è¾ƒå¤§çš„å› ç´ çš„å½±å“å˜å°
    )

    # 7.åˆ›å»ºå‘é‡æ•°æ®åº“
    try:
        vectordb = Chroma.from_documents(
            documents=splits,  # è¾“å…¥åˆ†å‰²åçš„æ–‡æœ¬å—
            embedding=embeddings,  # ä½¿ç”¨æŒ‡å®šçš„åµŒå…¥æ¨¡å‹
            persist_directory=Config.PERSIST_DIRECTORY  # å°†å½“å‰å†…å­˜ä¸­çš„å‘é‡æ•°æ®åº“ï¼ˆåŒ…æ‹¬ç´¢å¼•ã€å‘é‡æ•°æ®ã€å…ƒæ•°æ®ç­‰ï¼‰ä¿å­˜åˆ°æŒ‡å®šç›®å½•
        )
        print(f"å‘é‡æ•°æ®åº“å·²åˆ›å»ºå¹¶ä¿å­˜è‡³ï¼š{Config.PERSIST_DIRECTORY}")
    except Exception as e:
        print(f"åˆ›å»ºå‘é‡æ•°æ®åº“æ—¶å‡ºé”™: {str(e)}")
        # å°è¯•ä¸å¸¦ persist_directory åˆ›å»º
        vectordb = Chroma.from_documents(
            documents=splits,
            embedding=embeddings
        )
        print("å‘é‡æ•°æ®åº“æœªæŒä¹…åŒ–ï¼Œé‡å¯åéœ€é‡æ–°æ„å»º")

    print(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼åŒ…å« {len(documents)} ä¸ªæ–‡æ¡£ï¼Œ{len(splits)} ä¸ªæ–‡æœ¬å—")
    return vectordb  # è¿”å›å‘é‡æ•°æ®åº“å¯¹è±¡ä¾›åç»­ä½¿ç”¨


# äº” åˆ›å»ºæ£€ç´¢å™¨å‡½æ•°
def create_retrieve(vectordb):
    """åˆ›å»ºæ£€ç´¢å™¨ï¼Œè´Ÿè´£ä»å‘é‡åº“ä¸­æ‰¾å‡ºä¸é—®é¢˜ç›¸å…³çš„æ–‡æœ¬å—"""
    # æœç´¢æœ€ç›¸å…³çš„6ä¸ªæ–‡æœ¬å—
    retriever = vectordb.as_retriever(
        search_kwargs={'k': 6}  # k=x:fè¿”å›æœ€ç›¸ä¼¼çš„xä¸ªæ–‡æœ¬å—,éœ€ä¸ªå—å¹³è¡¡å›ç­”è´¨é‡ä¸å¤„ç†æ—¶é—´(è¿™ä¸ªå›ç­”ä¼šå¾ˆæ…¢,å—å¤ªå°‘å›ç­”è´¨é‡å¾ˆå·®)
    )
    return retriever


# å…­,MiniMax LLMå°è£…ç±»
class MiniMaxLLM:
    """å°è£…MiniMax APIè°ƒç”¨"""

    @staticmethod  # é™æ€æ–¹æ³•,ä¸ç”¨åˆ›å»ºç±»å®ä¾‹å³å¯è°ƒç”¨
    def invoke(prompt: str) -> str:  # ç±»å‹æç¤ºï¼šè¾“å…¥strï¼Œè¿”å›str
        """è°ƒç”¨MiniMax APIç”Ÿæˆå›å¤"""
        # å¤„ç†ä¸åŒæ ¼å¼çš„æç¤ºè¯è¾“å…¥
        if hasattr(prompt, 'to_string'):  # hasattr å‡½æ•°ç”¨äºæ£€æŸ¥å¯¹è±¡æ˜¯å¦å…·æœ‰æŒ‡å®šçš„å±æ€§æˆ–æ–¹æ³•ã€‚å®ƒæ¥å—ä¸¤ä¸ªå‚æ•°ï¼šå¯¹è±¡å’Œå±æ€§åï¼Œå¹¶è¿”å›ä¸€ä¸ªå¸ƒå°”å€¼ã€‚
            # æ£€æŸ¥promptæ˜¯å¦æœ‰to_stringæ–¹æ³•ï¼ˆå¯èƒ½æ˜¯PromptTemplateå¯¹è±¡ï¼‰
            prompt_content = prompt.to_string()
        elif not isinstance(prompt, str):
            # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            prompt_content = str(prompt)
        else:
            prompt_content = prompt  # å·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨

        # é€šå¸¸åœ¨ä½¿ç”¨APIæ—¶ï¼Œéœ€è¦è®¾ç½®è¯·æ±‚å¤´ï¼ˆheadersï¼‰ï¼Œä»¥æä¾›å¿…è¦çš„è®¤è¯ä¿¡æ¯å’ŒæŒ‡å®šè¯·æ±‚ä½“çš„æ ¼å¼
        headers = {
            'Authorization': f'Bearer {Config.MM_API_KEY}',  # Authorization: HTTPæ ‡å‡†è®¤è¯å¤´,Bearerä»¤ç‰Œè®¤è¯: ä¸€ç§è®¤è¯æ–¹æ¡ˆï¼ˆç±»ä¼¼"é’¥åŒ™"
            'Content-Type': 'application/json',  # Content-Type: å‘Šè¯‰æœåŠ¡å™¨è¯·æ±‚ä½“çš„æ ¼å¼,application/json: è¡¨ç¤ºæ•°æ®æ˜¯JSONæ ¼å¼
            "Group-Id": Config.MM_GROUP_ID,
        }
        # è¯·æ±‚ä½“é…ç½®
        payload = {
            'model': "abab5.5-chat",  # æŒ‡å®šæ¨¡å‹ç‰ˆæœ¬
            'messages': [
                {
                    'role': 'system',
                    'content': "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ï¼Œä¸¥æ ¼æ ¹æ®æä¾›çš„èµ„æ–™å›ç­”é—®é¢˜ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¯´æ˜'æ ¹æ®èµ„æ–™æ— æ³•å›ç­”æ­¤é—®é¢˜'ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt_content
                }
            ],
            "temperature": 0.1,  # æ¸©åº¦å‚æ•°ï¼šæ§åˆ¶éšæœºæ€§ï¼Œ0.1è¡¨ç¤ºä½éšæœºæ€§,ä¿è¯å›ç­”ç¨³å®šæ€§
            "top_p": 0.7,  # æ ¸é‡‡æ ·å‚æ•°ï¼šé™åˆ¶è¯æ±‡é€‰æ‹©èŒƒå›´
            "stream": False,  # éæµå¼å“åº”ï¼šä¸€æ¬¡æ€§è¿”å›å®Œæ•´ç­”æ¡ˆ
            "max_tokens": 1024,  # æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼š1024ä¸ªtoken
        }

        try:  # å¼‚å¸¸å¤„ç†ï¼šæ•è·å¯èƒ½çš„ç½‘ç»œæˆ–APIé”™è¯¯
            # å‘é€POSTè¯·æ±‚
            response = requests.post(
                Config.MM_API_URL,
                headers=headers,
                json=payload,  # è‡ªåŠ¨åºåˆ—åŒ–ä¸ºJSON
                timeout=30  # 30ç§’è¶…æ—¶
            )

            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if response.status_code != 200:
                # APIè°ƒç”¨å¤±è´¥
                error_msg = f" APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                try:
                    # å°è¯•è§£æé”™è¯¯è¯¦æƒ…
                    error_detail = response.json()
                    error_msg += f"\né”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, ensure_ascii=False)}"
                    # json.dumpsï¼šå°†Pythonå¯¹è±¡è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                    # ensure_ascii=Falseï¼šå…è®¸éASCIIå­—ç¬¦ï¼ˆå¦‚ä¸­æ–‡ï¼‰
                except:
                    # å¦‚æœå“åº”ä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥æ˜¾ç¤ºæ–‡æœ¬
                    error_msg += f"\nå“åº”å†…å®¹: {response.text[:500]}"
                    # åªæ˜¾ç¤ºå‰500å­—ç¬¦ï¼Œé¿å…è¿‡é•¿è¾“å‡º
                return error_msg

            # è§£ææˆåŠŸå“åº”
            result = response.json()  # å°†JSONå“åº”è½¬æ¢ä¸ºPythonå­—å…¸

            # æå–å›ç­”å†…å®¹ï¼ˆé€‚é…APIå¯èƒ½çš„ä¸åŒå“åº”æ ¼å¼ï¼‰
            if "choices" in result and result["choices"]:
                choice = result["choices"][0]  # è·å–ç¬¬ä¸€ä¸ªé€‰æ‹©
                if "message" in choice and "content" in choice["message"]:
                    return choice["message"]["content"]

            if "reply" in result:  # å¦ä¸€ç§å¯èƒ½çš„å“åº”æ ¼å¼
                return result["reply"]

            # æ— æ³•æå–ç­”æ¡ˆçš„æƒ…å†µ
            return f"æ— æ³•ä»APIå“åº”ä¸­æå–ç­”æ¡ˆ"

        except requests.exceptions.Timeout:
            # ç½‘ç»œè¶…æ—¶å¼‚å¸¸
            return "APIè¯·æ±‚è¶…æ—¶"
        except Exception as e:
            # å…¶ä»–æ‰€æœ‰å¼‚å¸¸
            return f"è°ƒç”¨APIæ—¶å‡ºé”™: {str(e)}"


# ä¸ƒã€Agentç±»ï¼ˆæ–°æ·»åŠ çš„éƒ¨åˆ†ï¼‰####################################################
class SimpleToolAgent:
    """ç®€å•çš„å·¥å…·è°ƒç”¨Agentï¼Œå®Œå…¨ç‹¬ç«‹äºRAGç³»ç»Ÿ"""

    def __init__(self, rag_chain):
        self.rag_chain = rag_chain  # ä¿ç•™ä½†ä¸ä½¿ç”¨

    def call_api_directly(self, prompt, system_prompt=None):
        """ç›´æ¥è°ƒç”¨MiniMax APIï¼Œå®Œå…¨ç»•è¿‡RAGçš„é™åˆ¶"""
        headers = {
            'Authorization': f'Bearer {Config.MM_API_KEY}',
            'Content-Type': 'application/json',
            "Group-Id": Config.MM_GROUP_ID,
        }

        # ä½¿ç”¨æ— é™åˆ¶çš„ç³»ç»Ÿæç¤ºè¯
        if system_prompt is None:
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœæ˜¯è®¡ç®—é—®é¢˜è¯·ç»™å‡ºè¯¦ç»†æ­¥éª¤ï¼Œå¦‚æœæ˜¯æ¦‚å¿µè§£é‡Šè¯·æ¸…æ™°è¯´æ˜ã€‚"

        payload = {
            'model': "abab5.5-chat",
            'messages': [
                {
                    'role': 'system',
                    'content': system_prompt
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.1,
            "top_p": 0.7,
            "stream": False,
            "max_tokens": 1024,
        }

        try:
            response = requests.post(
                Config.MM_API_URL,
                headers=headers,
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                if "choices" in result and result["choices"]:
                    return result["choices"][0]["message"]["content"]
                elif "reply" in result:
                    return result["reply"]
                else:
                    return "å·²å¤„ç†æ‚¨çš„è¯·æ±‚"
            else:
                return f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
        except Exception as e:
            return f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"

    def detect_task_type(self, question):
        """æ£€æµ‹é—®é¢˜ç±»å‹"""
        question_lower = question.lower()

        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤šæ­¥éª¤ä»»åŠ¡ï¼ˆå¿…é¡»åŒæ—¶æœ‰"å…ˆ"å’Œ"ç„¶å"ï¼‰
        if "å…ˆ" in question_lower and ("ç„¶å" in question_lower or "æ¥ç€" in question_lower):
            return "multi_step"
        elif any(word in question_lower for word in
                 ["è®¡ç®—", "ç­‰äº", "å¤šå°‘", "+", "-", "*", "/", "å¹³æ–¹", "åŠ ", "å‡", "ä¹˜", "é™¤"]):
            return "calculation"
        elif any(word in question_lower for word in ["è§£é‡Š", "ä»€ä¹ˆæ˜¯", "å®šä¹‰", "æ¦‚å¿µ", "è¯´æ˜"]):
            return "explanation"
        else:
            return "general"

    def split_multi_step(self, question):
        """åˆ†å‰²å¤šæ­¥éª¤é—®é¢˜"""
        # æ‰¾åˆ°åˆ†å‰²ç‚¹
        if "ç„¶å" in question:
            split_word = "ç„¶å"
        elif "æ¥ç€" in question:
            split_word = "æ¥ç€"
        else:
            return [question]

        parts = question.split(split_word)
        steps = []

        for part in parts:
            cleaned = part.strip()
            # å»æ‰"å…ˆ"å­—
            if cleaned.startswith("å…ˆ"):
                cleaned = cleaned[1:].strip()
            # å»æ‰å¼€å¤´çš„ä¸­æ–‡æ ‡ç‚¹
            cleaned = cleaned.lstrip('ï¼Œã€‚ï¼š:')
            if cleaned:
                steps.append(cleaned)

        return steps

    def process_single_step(self, question, step_type):
        """å¤„ç†å•æ­¥éª¤é—®é¢˜"""
        if step_type == "calculation":
            # è®¡ç®—é—®é¢˜
            prompt = f"è¯·è®¡ç®—è¿™ä¸ªé—®é¢˜ï¼š{question}ã€‚è¯·ç»™å‡ºè¯¦ç»†çš„è®¡ç®—æ­¥éª¤å’Œæœ€ç»ˆç»“æœã€‚"
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®è®¡ç®—ç”¨æˆ·çš„é—®é¢˜å¹¶ç»™å‡ºè¯¦ç»†æ­¥éª¤ã€‚"
            result = self.call_api_directly(prompt, system_prompt)
            return {
                "type": "è®¡ç®—",
                "result": result
            }
        elif step_type == "explanation":
            # è§£é‡Šé—®é¢˜
            prompt = f"è¯·è¯¦ç»†è§£é‡Šï¼š{question}ã€‚åŒ…æ‹¬ï¼š1.å®šä¹‰ 2.åŸç† 3.åº”ç”¨åœºæ™¯ 4.ç›¸å…³æŠ€æœ¯"
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶ï¼Œè¯·æ¸…æ™°å‡†ç¡®åœ°è§£é‡ŠæŠ€æœ¯æ¦‚å¿µã€‚"
            result = self.call_api_directly(prompt, system_prompt)
            return {
                "type": "è§£é‡Š",
                "result": result
            }
        else:
            # ä¸€èˆ¬é—®é¢˜
            result = self.call_api_directly(question)
            return {
                "type": "é€šç”¨",
                "result": result
            }

    def run(self, question):
        """ä¸»è¿è¡Œæ–¹æ³•"""
        task_type = self.detect_task_type(question)

        if task_type == "multi_step":
            # å¤„ç†å¤šæ­¥éª¤ä»»åŠ¡
            steps = self.split_multi_step(question)

            if len(steps) <= 1:
                # å¦‚æœä¸æ˜¯çœŸæ­£çš„å¤šæ­¥éª¤ï¼ŒæŒ‰å•æ­¥éª¤å¤„ç†
                step_type = self.detect_task_type(question)
                result = self.process_single_step(question, step_type)

                response = f"""
ğŸ¤– **Agentå·¥ä½œæµç¨‹**

**é—®é¢˜åˆ†æ**: {question} â†’ {result['type']}ä»»åŠ¡

**æ‰§è¡Œç»“æœ**:
{result['result']}

---
*Agentæ¼”ç¤ºï¼šå±•ç¤ºäº†å·¥å…·é€‰æ‹©å’Œæ‰§è¡Œè¿‡ç¨‹*
"""
                return response

            # å¤„ç†æ¯ä¸ªæ­¥éª¤
            step_results = []
            for i, step in enumerate(steps):
                step_type = self.detect_task_type(step)
                result = self.process_single_step(step, step_type)
                step_results.append({
                    "index": i + 1,
                    "step": step,
                    "type": result["type"],
                    "result": result["result"]
                })

            # æ„å»ºå¤šæ­¥éª¤å“åº”
            step_summary = []
            step_details = []

            for sr in step_results:
                step_summary.append(f"{sr['index']}. {sr['step']} â†’ {sr['type']}å·¥å…·")
                step_details.append(f"**æ­¥éª¤{sr['index']}** ({sr['type']}å·¥å…·):\n{sr['result']}")

            response = f"""
ğŸ¤– **å¤šæ­¥éª¤ä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Š**

**åŸå§‹é—®é¢˜**: {question}

**ä»»åŠ¡åˆ†è§£**:
{chr(10).join(step_summary)}

**æ‰§è¡Œç»“æœ**:
{chr(10).join(step_details)}

---
*Agentæ¼”ç¤ºï¼šå±•ç¤ºäº†å¤šæ­¥éª¤ä»»åŠ¡çš„å¤„ç†èƒ½åŠ›å’Œæ™ºèƒ½å·¥å…·é€‰æ‹©*
"""
            return response
        else:
            # å¤„ç†å•æ­¥éª¤ä»»åŠ¡
            result = self.process_single_step(question, task_type)

            response = f"""
ğŸ¤– **Agentå·¥ä½œæµç¨‹**

**é—®é¢˜åˆ†æ**: {question} â†’ {result['type']}ä»»åŠ¡

**æ‰§è¡Œç»“æœ**:
{result['result']}

---
*Agentæ¼”ç¤ºï¼šå±•ç¤ºäº†å·¥å…·é€‰æ‹©å’Œæ‰§è¡Œè¿‡ç¨‹*
"""
            return response
# å…« æ„å»ºRAGåº”ç”¨é“¾
def create_rag_chain(retriever):
    # å®šä¹‰æç¤ºè¯æ¨¡æ¿
    template = """è¯·ä¸¥æ ¼ä¾æ®ä»¥ä¸‹æä¾›çš„èƒŒæ™¯èµ„æ–™æ¥å›ç­”é—®é¢˜ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¯´æ˜"æ ¹æ®èµ„æ–™æ— æ³•å›ç­”æ­¤é—®é¢˜"ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚

    **ç‰¹åˆ«æŒ‡ä»¤**ï¼šå¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯è¦æ±‚æ€»ç»“ã€æ¦‚è¿°æˆ–å¯»æ‰¾ä¸»é¢˜ï¼Œè¯·ä½ ä»”ç»†åˆ†ææ‰€æœ‰æä¾›çš„èµ„æ–™ï¼Œè¿›è¡Œå½’çº³ã€åˆ†ç±»å’Œæ¦‚æ‹¬ï¼Œæ¢³ç†å‡ºæ¸…æ™°çš„ç»“æ„ã€‚

    èƒŒæ™¯èµ„æ–™ï¼š
    {context}  # å ä½ç¬¦ï¼šå°†è¢«æ£€ç´¢åˆ°çš„æ–‡æ¡£æ›¿æ¢

    é—®é¢˜ï¼š{question}  # å ä½ç¬¦ï¼šå°†è¢«ç”¨æˆ·é—®é¢˜æ›¿æ¢

    è¯·åŸºäºèµ„æ–™æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ï¼š"""

    # åˆ›å»ºpromptTemplateå¯¹è±¡
    prompt = PromptTemplate.from_template(template)  # ä»templateæ¨¡æ¿å­—ç¬¦ä¸²åˆ›å»ºæç¤ºè¯æ¨¡æ¿

    # å®šä¹‰æ–‡æ¡£æ ¼å¼åŒ–å‡½æ•°
    def format_docs(docs):
        # å°†Documentå¯¹è±¡åˆ—è¡¨è¿æ¥ä¸ºå•ä¸ªå­—ç¬¦ä¸²
        return '\n\n'.join([doc.page_content for doc in docs])  ## åˆ—è¡¨æ¨å¯¼å¼ï¼šæå–æ¯ä¸ªDocumentçš„page_content

    # ä½¿ç”¨LangChainè¡¨è¾¾å¼è¯­è¨€(LCEL)æ„å»ºå¤„ç†é“¾,æ£€ç´¢ -> æ ¼å¼åŒ– -> ç”Ÿæˆ
    rag_chain = (
        # 1.å‡†å¤‡è¾“å…¥æ•°æ®å­—å…¸
            {'context': retriever | format_docs, 'question': RunnablePassthrough()}  # retriever|format_docså…ˆæ£€ç´¢å†æ ¼å¼åŒ–
            | prompt  # å¡«å……æç¤ºè¯æ¨¡æ¿
            | MiniMaxLLM.invoke  # è°ƒç”¨LLMæ ¹æ®æç¤ºè¯ç”Ÿæˆå›ç­”
            | StrOutputParser()
    )
    return rag_chain


# ä¹ Gradioç•Œé¢ç±»(Webå‰ç«¯æ„å»º)
class ChatInterface:
    def __init__(self, rag_chain):
        self.rag_chain = rag_chain  # ä¿å­˜RAGé“¾
        self.chat_history = []  # å­˜å‚¨å¯¹è¯å†å²
        self.agent = SimpleToolAgent(rag_chain)  # æ–°åŠ ï¼šåˆ›å»ºAgentå®ä¾‹
        self.mode = "rag"  # æ–°åŠ ï¼šæ¨¡å¼æ ‡è®°ï¼Œrag æˆ– agent

    def change_mode(self, new_mode):
        """åˆ‡æ¢æ¨¡å¼"""
        self.mode = new_mode
        if new_mode == "agent":
            return "ğŸ¤– å·²åˆ‡æ¢åˆ°Agentæ¨¡å¼ï¼ç°åœ¨æˆ‘ä¼šå±•ç¤ºå·¥å…·é€‰æ‹©å’Œå†³ç­–è¿‡ç¨‹ã€‚"
        else:
            return "ğŸ” å·²åˆ‡æ¢åˆ°RAGæ¨¡å¼ï¼ˆçº¯æ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ã€‚"

    def add_message(self, role, content):
        """æ·»åŠ æ¶ˆæ¯åˆ°èŠå¤©å†å²"""
        self.chat_history.append({"role": role, "content": content})

    def respond(self, message, chat_history):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶è¿”å›å“åº”"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡å¼åˆ‡æ¢å‘½ä»¤
        if message.lower() in ["/agent", "/rag", "/mode agent", "/mode rag"]:
            if "agent" in message.lower():
                reply = self.change_mode("agent")
            else:
                reply = self.change_mode("rag")
            self.add_message("assistant", reply)
            return self.chat_history

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.add_message("user", message)

        try:
            # æ˜¾ç¤ºæ€è€ƒçŠ¶æ€
            thinking_msg = "æ­£åœ¨æ€è€ƒ..."
            self.add_message("assistant", thinking_msg)

            # æ ¹æ®æ¨¡å¼é€‰æ‹©å¤„ç†æ–¹å¼
            if self.mode == "agent":
                # ä½¿ç”¨Agentå¤„ç†
                answer = self.agent.run(message)
            else:
                # ä½¿ç”¨çº¯RAGå¤„ç†
                answer = self.rag_chain.invoke(message)

            # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯ä¸ºå®é™…å›ç­”
            self.chat_history[-1] = {"role": "assistant", "content": answer}

            # è¿”å›æ›´æ–°åçš„èŠå¤©å†å²
            return self.chat_history
        except Exception as e:
            error_msg = f"ç³»ç»Ÿé”™è¯¯: {str(e)}"
            self.add_message("assistant", error_msg)
            return self.chat_history

    def clear_chat(self):
        """æ¸…ç©ºèŠå¤©å†å²"""
        self.chat_history = []
        self.mode = "rag"  # æ¸…ç©ºæ—¶é‡ç½®æ¨¡å¼
        return []

    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        with gr.Blocks(title="æ™ºèƒ½çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ - RAG + Agentæ¼”ç¤º") as interface:

            # æ ‡é¢˜åŒºåŸŸ
            gr.Markdown("# æ™ºèƒ½çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ")
            gr.Markdown("**RAG + Agent æ¼”ç¤ºç³»ç»Ÿ** - å±•ç¤ºæ£€ç´¢å¢å¼ºç”Ÿæˆä¸Agentå·¥å…·è°ƒç”¨")

            with gr.Row():
                with gr.Column(scale=3):
                    # èŠå¤©æœºå™¨äººç»„ä»¶
                    chatbot = gr.Chatbot(
                        height=500,
                        label="å¯¹è¯è®°å½•",
                        value=self.chat_history
                    )

                    # è¾“å…¥åŒºåŸŸ
                    with gr.Row():
                        msg = gr.Textbox(
                            placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜... è¾“å…¥ /agent åˆ‡æ¢Agentæ¨¡å¼ï¼Œ/rag åˆ‡æ¢RAGæ¨¡å¼",
                            show_label=False,
                            scale=4,
                            container=False,
                            lines=2
                        )
                        submit_btn = gr.Button("å‘é€", variant="primary", scale=1)

                    # åŠŸèƒ½æŒ‰é’®è¡Œ
                    with gr.Row():
                        clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary")

                with gr.Column(scale=1):
                    # ç³»ç»Ÿä¿¡æ¯é¢æ¿ï¼ˆæ–°åŠ æ¨¡å¼æ˜¾ç¤ºï¼‰
                    gr.Markdown("### ç³»ç»Ÿä¿¡æ¯")

                    # å½“å‰æ¨¡å¼æ˜¾ç¤º
                    mode_display = gr.Markdown(
                        f"**å½“å‰æ¨¡å¼**: {'ğŸ¤– Agentæ¨¡å¼' if self.mode == 'agent' else 'ğŸ” RAGæ¨¡å¼'}")

                    # æ¨¡å¼åˆ‡æ¢æŒ‰é’®ï¼ˆæ–°åŠ ï¼‰
                    gr.Markdown("### æ¨¡å¼åˆ‡æ¢")
                    with gr.Row():
                        agent_btn = gr.Button("åˆ‡æ¢åˆ°ğŸ¤– Agentæ¨¡å¼", variant="primary")
                        rag_btn = gr.Button("åˆ‡æ¢åˆ°ğŸ” RAGæ¨¡å¼", variant="secondary")

                    # AgentåŠŸèƒ½ä»‹ç»ï¼ˆæ–°åŠ ï¼‰
                    gr.Markdown("""
                    **ğŸ¤– Agentæ¨¡å¼åŠŸèƒ½ï¼š**
                    1. è‡ªåŠ¨é€‰æ‹©å·¥å…·ï¼ˆæœç´¢/è®¡ç®—/è§£é‡Šï¼‰
                    2. å±•ç¤ºå†³ç­–è¿‡ç¨‹
                    3. å¤šå·¥å…·åä½œæ¼”ç¤º

                    **å¯ç”¨å‘½ä»¤ï¼š**
                    - `/agent` æˆ– `/mode agent`ï¼šåˆ‡æ¢åˆ°Agentæ¨¡å¼
                    - `/rag` æˆ– `/mode rag`ï¼šåˆ‡æ¢åˆ°RAGæ¨¡å¼
                    """)

                    # ç¤ºä¾‹é—®é¢˜åŒºåŸŸï¼ˆå¢åŠ Agentç¤ºä¾‹ï¼‰
                    gr.Markdown("### è¯•è¯•è¿™äº›é—®é¢˜ï¼š")

                    # æ™®é€šç¤ºä¾‹é—®é¢˜
                    examples = [
                        "ç¥ç»ç½‘ç»œçš„æ¦‚å¿µ",
                        "ä¸ºä»€ä¹ˆè¦åˆ†è¯å’Œç¼–ç ",
                        "æ¦‚æ‹¬ä¸‹æ³¨æ„åŠ›å¤´æ•°çš„ä½œç”¨",
                    ]

                    # Agentæ¨¡å¼ä¸“ç”¨ç¤ºä¾‹ï¼ˆæ–°åŠ ï¼‰
                    agent_examples = [
                        "è®¡ç®—ä¸€ä¸‹(15 + 27) * 3ç­‰äºå¤šå°‘",
                        "è§£é‡Šä¸€ä¸‹Transformerçš„æ¦‚å¿µ",
                        "å…ˆè®¡ç®—3çš„å¹³æ–¹ï¼Œç„¶åè§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æœºåˆ¶",
                        "ä»€ä¹ˆæ˜¯æ¢¯åº¦ä¸‹é™ï¼Ÿè®¡ç®—ä¸€ä¸‹10çš„å¹³æ–¹æ ¹",
                    ]

                    gr.Markdown("**æ™®é€šé—®é¢˜ï¼š**")
                    for example in examples:
                        btn = gr.Button(
                            example[:25] + "..." if len(example) > 25 else example,
                            size="sm",
                            variant="secondary"
                        )
                        btn.click(lambda q=example: q, None, msg)

                    gr.Markdown("**Agentæ¼”ç¤ºé—®é¢˜ï¼š**")
                    for example in agent_examples:
                        btn = gr.Button(
                            example[:25] + "..." if len(example) > 25 else example,
                            size="sm",
                            variant="primary"
                        )
                        btn.click(lambda q=example: q, None, msg)

            # äº‹ä»¶ç»‘å®š
            # å‘é€æŒ‰é’®
            submit_btn.click(
                fn=self.respond,
                inputs=[msg, chatbot],
                outputs=[chatbot]
            ).then(
                lambda: "", None, msg
            )

            # å›è½¦å‘é€
            msg.submit(
                fn=self.respond,
                inputs=[msg, chatbot],
                outputs=[chatbot]
            ).then(
                lambda: "", None, msg
            )

            # æ¸…ç©ºå¯¹è¯
            clear_btn.click(
                fn=self.clear_chat,
                inputs=None,
                outputs=[chatbot]
            )

            # æ¨¡å¼åˆ‡æ¢æŒ‰é’®äº‹ä»¶ï¼ˆæ–°åŠ ï¼‰
            def switch_to_agent():
                return "/agent"

            def switch_to_rag():
                return "/rag"

            agent_btn.click(
                fn=switch_to_agent,
                inputs=None,
                outputs=msg
            )

            rag_btn.click(
                fn=switch_to_rag,
                inputs=None,
                outputs=msg
            )

            # æ›´æ–°æ¨¡å¼æ˜¾ç¤ºçš„å“åº”å‡½æ•°ï¼ˆæ–°åŠ ï¼‰
            agent_btn.click(
                fn=lambda: "**å½“å‰æ¨¡å¼**: ğŸ¤– Agentæ¨¡å¼",
                inputs=None,
                outputs=mode_display
            )

            rag_btn.click(
                fn=lambda: "**å½“å‰æ¨¡å¼**: ğŸ” RAGæ¨¡å¼",
                inputs=None,
                outputs=mode_display
            )

        return interface


# å ä¸»å‡½æ•°(ç¨‹åºå…¥å£)
def main():
    # æ ‡é¢˜
    print('=' * 50)
    print('ä¸ªäººçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ(RAG) - åŒ…å«Agentæ¼”ç¤º')
    print('=' * 50)

    # æ˜¾ç¤ºçŸ¥è¯†åº“ä¿¡æ¯
    print(f"çŸ¥è¯†åº“ç›®å½•: {Config.KNOWLEDGE_BASE_PATH}")

    if os.path.exists(Config.KNOWLEDGE_BASE_PATH):
        md_files = []
        for root, dirs, files in os.walk(Config.KNOWLEDGE_BASE_PATH):
            for file in files:
                if file.endswith('.md'):
                    md_files.append(os.path.join(root, file))

        print(f"å‘ç° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
        if len(md_files) > 0:
            print("æ‚¨çš„ç¬”è®°æ–‡ä»¶:")
            for i, file in enumerate(md_files[:8]):
                print(f"  {i + 1}. {os.path.basename(file)}")
            if len(md_files) > 8:
                print(f"  ... è¿˜æœ‰ {len(md_files) - 8} ä¸ªæ–‡ä»¶")
        else:
            print(" çŸ¥è¯†åº“ç›®å½•ä¸­æ²¡æœ‰Markdownæ–‡ä»¶")
            print(f"è¯·å°†çŸ¥è¯†åº“æ–‡ä»¶å¤åˆ¶åˆ° {Config.KNOWLEDGE_BASE_PATH} ç›®å½•ä¸­")
    else:
        print(f"çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨")

    # åˆå§‹åŒ–çŸ¥è¯†åº“
    if not os.path.exists(Config.PERSIST_DIRECTORY):
        # æ£€æŸ¥å‘é‡æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        print("æœªæ‰¾åˆ°å·²æ„å»ºçš„çŸ¥è¯†åº“ï¼Œå¼€å§‹åˆå§‹åŒ–...")
        vectordb = build_knowledge_base()  # è°ƒç”¨å‡½æ•°æ„å»ºå‘é‡çŸ¥è¯†åº“
    else:
        print('åŠ è½½å·²æœ‰çŸ¥è¯†åº“')
        embeddings = HuggingFaceEmbeddings(model_name=Config.EMBED_MODEL_NAME)
        vectordb = Chroma(
            persist_directory=Config.PERSIST_DIRECTORY,  # å‘é‡æ•°æ®å­˜å‚¨ä½ç½®
            embedding_function=embeddings  # ä½¿ç”¨æŒ‡å®šæ¨¡å‹è¿›è¡Œå‘é‡åŒ–
        )

    # åˆ›å»ºRAGé“¾
    retriever = create_retrieve(vectordb)
    rag_chain = create_rag_chain(retriever)

    print('=' * 50)
    print('ğŸ¤– AgentåŠŸèƒ½å·²å¯ç”¨ï¼')
    print('å¯ç”¨å‘½ä»¤ï¼š')
    print('  - /agent æˆ– /mode agentï¼šåˆ‡æ¢åˆ°Agentæ¨¡å¼')
    print('  - /rag æˆ– /mode ragï¼šåˆ‡æ¢åˆ°RAGæ¨¡å¼')
    print('=' * 50)
    print('ç³»ç»Ÿå‡†å¤‡å°±ç»ª')
    print('æ­£åœ¨å¯åŠ¨Webç•Œé¢...')

    # åˆ›å»ºå¹¶å¯åŠ¨Gradioç•Œé¢
    chat_interface = ChatInterface(rag_chain)
    interface = chat_interface.create_interface()

    print("è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼šhttp://localhost:7860")
    print("ç•Œé¢ä¸­æœ‰ä¸“é—¨çš„Agentæ¼”ç¤ºåŒºåŸŸå’Œç¤ºä¾‹é—®é¢˜")

    # å¯åŠ¨GradioæœåŠ¡å™¨
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False,
        theme=gr.themes.Soft()
    )


# ç¨‹åºå…¥å£ç‚¹
if __name__ == "__main__":
    main()